{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from bundle_adjuster import BundleAdjuster\n",
    "#from camera import Camera\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial.transform import Rotation # TODO: remove when not required\n",
    "\n",
    "def warp_two_images(img1, img2, H):\n",
    "  '''warp img2 to img1 with homography H'''\n",
    "  h1,w1 = img1.shape[:2]\n",
    "  h2,w2 = img2.shape[:2]\n",
    "\n",
    "  pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "  pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "\n",
    "  pts2_ = cv.perspectiveTransform(pts2, H)\n",
    "  pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "\n",
    "  [x_min, y_min] = np.int32(pts.min(axis=0).ravel())\n",
    "  [x_max, y_max] = np.int32(pts.max(axis=0).ravel())\n",
    "\n",
    "  t = [-x_min,-y_min]\n",
    "  Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate by t\n",
    "\n",
    "  # b_channel, g_channel, r_channel = cv.split(img1)\n",
    "  # alpha_channel = np.ones(b_channel.shape, dtype=b_channel.dtype) * 50 #creating a dummy alpha channel image.\n",
    "  # img1 = cv.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "\n",
    "  result = cv.warpPerspective(img2, Ht.dot(H), (x_max-x_min, y_max-y_min))\n",
    "  result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "class CameraEstimator:\n",
    "\n",
    "  def __init__(self, matches):\n",
    "    self._matches = matches\n",
    "\n",
    "    # for match in self._matches:\n",
    "      # match.cam_from, match.cam_to = match.cam_to, match.cam_from\n",
    "      # match.H = np.linalg.pinv(match.H)\n",
    "      # self._normalise_match_H(match)\n",
    "      # match.cam_from, match.cam_to = match.cam_to, match.cam_from\n",
    "      # print(f'H: {match.H}\\n')\n",
    "      # for inlier in match.inliers:\n",
    "      #   inlier[0], inlier[1] = inlier[1], inlier[0]\n",
    "\n",
    "\n",
    "  def estimate(self):\n",
    "\n",
    "    for m in self._matches:\n",
    "      print(f'Match (unordered) {m.cam_from.image.filename} and {m.cam_to.image.filename}: {len(m.inliers)}')\n",
    "      # for match in matcher.matches:\n",
    "      # result = warp_two_images(m.cam_to.image.image, m.cam_from.image.image, m.H)\n",
    "      # cv.imshow('Result', result)\n",
    "      # cv.waitKey(0)\n",
    "\n",
    "    self._estimate_focal()\n",
    "    add_order = self._max_span_tree_order_2()\n",
    "\n",
    "    # Display order\n",
    "    print(f'Add order:')\n",
    "    for (i,m) in enumerate(add_order):\n",
    "      print(f'  {i} => Match {m.cam_from.image.filename} and {m.cam_to.image.filename}: {len(m.inliers)}')\n",
    "    # return\n",
    "\n",
    "    self._bundle_adjustment(add_order)\n",
    "\n",
    "    return self._all_cameras()\n",
    "\n",
    "\n",
    "  def _estimate_focal(self):\n",
    "    # Iterate through all matches and find median focal length. Set this for all cameras\n",
    "    focals = []\n",
    "    for match in self._matches:\n",
    "      focal_estimate = match.estimate_focal_from_homography()\n",
    "      if (focal_estimate != 0):\n",
    "        print(f'{match.cam_from.image.filename} to {match.cam_to.image.filename}: {focal_estimate}')\n",
    "        focals.append(focal_estimate)\n",
    "    median_focal = np.median(focals)\n",
    "\n",
    "    print(f'Focal set to: {median_focal}')\n",
    "\n",
    "    # if (len(focals) == 0):\n",
    "    median_focal = 1580\n",
    "\n",
    "    for camera in self._all_cameras():\n",
    "      camera.focal = median_focal\n",
    "\n",
    "\n",
    "  def _all_cameras(self):\n",
    "    all_cameras = set()\n",
    "\n",
    "    for match in self._matches:\n",
    "      all_cameras.add(match.cam_from)\n",
    "      all_cameras.add(match.cam_to)\n",
    "\n",
    "    return all_cameras\n",
    "\n",
    "\n",
    "  def _max_span_tree_order(self):\n",
    "    '''\n",
    "    Finds a maximum spanning tree from all matches and sorts\n",
    "    them into most connected matches in descending order. This\n",
    "    is the optimal order to add them to the BundleAdjuster\n",
    "    '''\n",
    "    sorted_matches = [self._matches[0]]\n",
    "    connected_cameras = set(self._matches[0].cams())\n",
    "    while (len(sorted_matches) < len(self._matches)):\n",
    "      for match in self._matches[1:]:\n",
    "        if (match.cam_to in connected_cameras or match.cam_from in connected_cameras):\n",
    "          sorted_matches.append(match)\n",
    "          connected_cameras.update(match.cams())\n",
    "\n",
    "    self._matches = sorted_matches\n",
    "\n",
    "\n",
    "  def _reverse_match(self, match):\n",
    "    match.cam_from, match.cam_to = match.cam_to, match.cam_from\n",
    "    match.H = np.linalg.pinv(match.H)\n",
    "    for inlier in match.inliers:\n",
    "      inlier[0], inlier[1] = inlier[1], inlier[0]\n",
    "    self._normalise_match_H(match)\n",
    "\n",
    "\n",
    "  def _normalise_match_H(self, match):\n",
    "    match.H = np.multiply(match.H, 1 / match.H[2][2])\n",
    "\n",
    "\n",
    "  def _max_span_tree_order_2(self):\n",
    "    '''\n",
    "    Finds a maximum spanning tree from all matches, with most connected edge as start point\n",
    "    '''\n",
    "    connected_nodes = set()\n",
    "    all_cameras = self._all_cameras()\n",
    "    sorted_all_cameras = sorted(all_cameras, key=lambda c:c.image.filename)\n",
    "    [print(c.image.filename) for c in sorted_all_cameras]\n",
    "    sorted_edges = sorted(self._matches, key=lambda m: len(m.inliers), reverse=True)\n",
    "    [print(f'{e.cam_from.image.filename} - {e.cam_to.image.filename}: {len(e.inliers)}') for e in sorted_edges]\n",
    "    best_edge = sorted_edges.pop(0)\n",
    "\n",
    "    # if (sorted_all_cameras.index(best_edge.cam_from) > sorted_all_cameras.index(best_edge.cam_to)):\n",
    "    #   print(\"edge swapped\")\n",
    "    #   self._reverse_match(best_edge)\n",
    "    # else:\n",
    "    #   self._normalise_match_H(best_edge)\n",
    "\n",
    "    print(f'Best edge: {best_edge.cam_from.image.filename} - {best_edge.cam_to.image.filename}: {len(best_edge.inliers)}')\n",
    "    print(f'Best edge H: {best_edge.H}')\n",
    "\n",
    "    add_order = [best_edge]\n",
    "    connected_nodes.add(best_edge.cam_from)\n",
    "    connected_nodes.add(best_edge.cam_to)\n",
    "\n",
    "    while (len(connected_nodes) < len(sorted_all_cameras)):\n",
    "      for (i, match) in enumerate(sorted_edges):\n",
    "        if (match.cam_from in connected_nodes):\n",
    "          # Add node as is\n",
    "          edge = sorted_edges.pop(i)\n",
    "          self._normalise_match_H(edge)\n",
    "          add_order.append(edge)\n",
    "          connected_nodes.add(edge.cam_from)\n",
    "          connected_nodes.add(edge.cam_to)\n",
    "          break\n",
    "        elif (match.cam_to in connected_nodes):\n",
    "          # Reverse node and add\n",
    "          edge = sorted_edges.pop(i)\n",
    "\n",
    "          self._reverse_match(edge)\n",
    "\n",
    "          add_order.append(edge)\n",
    "          connected_nodes.add(edge.cam_from)\n",
    "          connected_nodes.add(edge.cam_to)\n",
    "          break\n",
    "    \n",
    "    return add_order\n",
    "\n",
    "\n",
    "\n",
    "  def _bundle_adjustment(self, add_order):\n",
    "    '''\n",
    "    Iteratively add each match to the bundle adjuster\n",
    "    '''\n",
    "    \n",
    "    # #-------start-----------\n",
    "    # matches_to_add = self._matches.copy()\n",
    "    # added_cameras = set()\n",
    "    # ba = BundleAdjuster()\n",
    "\n",
    "    # # Intialise the first camera that will be used as reference frame\n",
    "    # first_cam = self._matches[0].cam_from\n",
    "    # first_cam.R = np.identity(3)\n",
    "    # first_cam.ppx, first_cam.ppy = 0, 0\n",
    "    # added_cameras.add(first_cam)\n",
    "\n",
    "    # while (len(matches_to_add) > 0):\n",
    "    #   match = matches_to_add.pop(0)\n",
    "\n",
    "    #   # Find which camera R needs to be estimated for\n",
    "    #   if (match.cam_from in added_cameras):\n",
    "    #     # cam_to_R = np.linalg.pinv(match.cam_to.K) @ match.H @ match.cam_from.K @ match.cam_from.R\n",
    "    #     cam_to_R = (np.linalg.pinv(match.cam_from.R) @ (np.linalg.pinv(match.cam_from.K) @ match.H @ match.cam_to.K)).T\n",
    "    #     match.cam_to.R = cam_to_R\n",
    "    #     match.cam_to.ppx, match.cam_to.ppy = 0, 0\n",
    "    #     print(f'{match.cam_from.image.filename} to {match.cam_to.image.filename}:\\n {match.cam_to.R}\\n\\n')\n",
    "    #   # elif (match.cam_to in added_cameras):\n",
    "    #   #   print('to -> from match found')\n",
    "    #   #   # print(f'np.linalg.pinv(match.cam_from.K): {np.linalg.pinv(match.cam_from.K)}')\n",
    "    #   #   # print(f'np.linalg.pinv(match.H): {np.linalg.pinv(match.H)}')\n",
    "    #   #   # print(f'match.cam_from.K: {match.cam_from.K}')\n",
    "    #   #   # print(f'match.cam_from.R: {match.cam_from.R}')\n",
    "    #   #   cam_from_R = np.linalg.pinv(match.cam_from.K) @ np.linalg.pinv(match.H) @ match.cam_to.K @ match.cam_to.R \n",
    "    #   #   match.cam_from.R = cam_from_R\n",
    "    #   #   match.cam_from.ppx, match.cam_from.ppy = 0, 0\n",
    "    #   #   print(f'{match.cam_from.image.filename} - {match.cam_from.R}')\n",
    "\n",
    "    #   # ba.add(match)\n",
    "    #   added_cameras.update(match.cams())\n",
    "\n",
    "      # for (i, match) in enumerate(matches_to_add):\n",
    "      #   # If both cameras already added, add the match to BA\n",
    "      #   if (match.cam_from in added_cameras and match.cam_to in added_cameras):\n",
    "      #     ba.add(matches_to_add.pop(i))\n",
    "      \n",
    "    #   #ba.run()\n",
    "    #   #-----end---------\n",
    "\n",
    "    ba = BundleAdjuster()\n",
    "\n",
    "    other_matches = set(self._matches) - set(add_order)\n",
    "\n",
    "    # print(f'Total matches: {len(self._matches)}')\n",
    "    # print(f'add_order count: {len(add_order)}')\n",
    "    # print(f'other_matches count: {len(other_matches)}')\n",
    "\n",
    "    identity_cam = add_order[0].cam_from\n",
    "    identity_cam.R = np.identity(3)\n",
    "    identity_cam.ppx, identity_cam.ppy = 0, 0\n",
    "\n",
    "    print(f'Identity cam: {identity_cam.image.filename}')\n",
    "\n",
    "    print('Original match params:')\n",
    "    for match in add_order:\n",
    "      print(f'{match.cam_from.image.filename} to {match.cam_to.image.filename}:\\n {match.cam_to.R}\\n')\n",
    "    print('------------------')\n",
    "\n",
    "    for match in add_order:\n",
    "      # result = warp_two_images(match.cam_from.image.image, match.cam_to.image.image, match.H)\n",
    "      # cv.imshow('Original H from RANSAC', result)\n",
    "      print(f'match.cam_from.R: {match.cam_from.R}')\n",
    "      print(f'match.cam_from.K: {match.cam_from.K}')\n",
    "      print(f'match.H: {match.H}')\n",
    "      print(f'match.cam_to.K: {match.cam_to.K}')\n",
    "\n",
    "      match.cam_to.R = (match.cam_from.R.T @ (np.linalg.pinv(match.cam_from.K) @ match.H @ match.cam_to.K)).T\n",
    "      match.cam_to.ppx, match.cam_to.ppy = 0, 0\n",
    "      print(f'{match.cam_from.image.filename} to {match.cam_to.image.filename}:\\n {match.cam_to.R}\\n')\n",
    "\n",
    "      # reconstructed_H = match.cam_from.K @ match.cam_from.R @ match.cam_to.R.T @ np.linalg.pinv(match.cam_to.K)\n",
    "      # result = warp_two_images(match.cam_from.image.image, match.cam_to.image.image, reconstructed_H)\n",
    "      # cv.imshow('Result with reconstructed H', result)\n",
    "\n",
    "      # # Matrix -> rotvec -> matrix\n",
    "      # converted_R = match.cam_to.rotvec_to_matrix(match.cam_to.angle_parameterisation())\n",
    "      # print(f'homography:\\n{match.H}')\n",
    "      # print(f'converted_R matrix:\\n{converted_R}')\n",
    "      # reconstructed_from_converted_R_H = match.cam_from.K @ match.cam_from.R @ converted_R.T @ np.linalg.pinv(match.cam_to.K)\n",
    "      # result = warp_two_images(match.cam_from.image.image, match.cam_to.image.image, reconstructed_from_converted_R_H)\n",
    "      # cv.imshow('Result with reconstructed H from converted R', result)\n",
    "      # cv.waitKey(0)\n",
    "      # return\n",
    "\n",
    "      ba.add(match)\n",
    "\n",
    "      added_cams = ba.added_cameras()\n",
    "      to_add = set()\n",
    "      for other_match in other_matches:\n",
    "        # If both cameras already added, add the match to BA\n",
    "        if (other_match.cam_from in added_cams and other_match.cam_to in added_cams):\n",
    "          to_add.add(other_match)\n",
    "      for match in to_add:\n",
    "        # self._reverse_match(match)\n",
    "        ba.add(match)\n",
    "        other_matches.remove(match)\n",
    "    # return\n",
    "    \n",
    "    all_cameras = None\n",
    "    try:\n",
    "      all_cameras = pickle.load(open(f'all_cameras_{len(self._all_cameras())}.p', 'rb'))\n",
    "\n",
    "      for match in self._matches:\n",
    "        for cam in all_cameras:\n",
    "          if (match.cam_to.image.filename == cam.image.filename):\n",
    "            match.cam_to = cam\n",
    "          elif (match.cam_from.image.filename == cam.image.filename):\n",
    "            match.cam_from = cam\n",
    "\n",
    "    except (OSError, IOError):    \n",
    "      ba.run()\n",
    "      all_cameras = self._all_cameras()\n",
    "      pickle.dump(all_cameras, open(f'all_cameras_{len(self._all_cameras())}.p', 'wb'))\n",
    "\n",
    "    print('BA complete.')\n",
    "\n",
    "    return\n",
    "\n",
    "    # print('Showing new homographies')\n",
    "\n",
    "    # # Get identity camera\n",
    "    # identity_cam = None\n",
    "    # for cam in all_cameras:\n",
    "    #   R = cam.R\n",
    "    #   if ((R.shape[0] == R.shape[1]) and np.allclose(R, np.eye(R.shape[0]))):\n",
    "    #     identity_cam = cam\n",
    "    #     break\n",
    "    \n",
    "    # if (identity_cam == None):\n",
    "    #   raise ValueError('No identity camera found')\n",
    "\n",
    "    # # panoImg = identity_cam.image.image\n",
    "    # # Iterate through all non-identity cameras, adding to final panorama image\n",
    "    # for cam in all_cameras:\n",
    "    #   if (cam != identity_cam):\n",
    "    #     print(f'identity_cam.K: {identity_cam.K}')\n",
    "    #     print(f'cam.K: {cam.K}')\n",
    "    #     constructed_from_converted_R_H = identity_cam.K @ identity_cam.R @ cam.R.T @ np.linalg.pinv(cam.K)\n",
    "    #     result = warp_two_images(identity_cam.image.image, cam.image.image, constructed_from_converted_R_H)\n",
    "    #     cv.imshow(f'Match {identity_cam.image.filename} to {match.cam_to.image.filename}, H from R', result)\n",
    "    #     cv.waitKey(0)\n",
    "    \n",
    "    # for match in self._matches:\n",
    "    #   constructed_from_converted_R_H = match.cam_from.K @ match.cam_from.R @ match.cam_to.R.T @ np.linalg.pinv(match.cam_to.K)\n",
    "    #   result = warp_two_images(match.cam_from.image.image, match.cam_to.image.image, constructed_from_converted_R_H)\n",
    "    #   cv.imshow(f'Match {match.cam_from.image.filename} to {match.cam_to.image.filename}, H from R', result)\n",
    "    #   cv.waitKey(0)\n",
    "\n",
    "      # return\n",
    "\n",
    "    # print('---------------------------------')\n",
    "    # print(\"------ Actual BA ----------------\")\n",
    "    # testBA = BundleAdjuster()\n",
    "    # testMatches = ba.matches()\n",
    "\n",
    "    # testBA.add(testMatches[3])\n",
    "    # testBA.add(testMatches[4])\n",
    "    # testBA.add(testMatches[1])\n",
    "    # testBA.add(testMatches[2])\n",
    "    # self._reverse_match(testMatches[0])\n",
    "    # testBA.add(testMatches[0])\n",
    "\n",
    "    # testBA.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
